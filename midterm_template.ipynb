{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aQoMk--DCfN"
   },
   "source": [
    "This template notebook should serve as a guide for how to load and manipulate the dataset, and the different preprocessing methods you may choose to implement (you are welcome to try any others outside of what is provided here). This code should be treated as pseudo-code - and you may have to debug this code to get it working adequately.\n",
    "\n",
    "In this notebook, we only access the labeled portion of the training dataset, and directly run/train/fit supervised methods. e.g., Multinomial Naive Bayes and Linear SGD classifiers (linear SGD [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html] implements regularized linear models with stochastic gradient descent, e.g., by choosing loss=‘log_loss’, you obtain a logistic regression classifier), on only this labeled portion of the training dataset. The performance values you get from running this experiment will serve as your baseline.\n",
    "\n",
    "Once you have these baseline numbers for the configuration of preprocessing and supervised methods you choose (ideally at least 2 preprocessing methods and also at least 2 supervised methods), you can now begin working on Part 1: i.e. using unsupervised learning methods to automate adding labels to the unlabelled portion of the train dataset. The goal is to see if adding these newly labeled data examples to the train set will improve the baseline numbers you obtained (i.e. Part 2: running the supervised methods you chose for the baseline on the newly augmented dataset and reporting the performance on this augmented dataset).\n",
    "\n",
    "Lastly, please note that there is a class imbalance in the train, test, and val sets. You will have to incorporate an approach to deal with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "LX0ia6JVtFjr"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as sk_OLS\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.semi_supervised import LabelPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD0dQabauB7z"
   },
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "uRBDrBxYtBbk"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "val_data = pd.read_csv(\"./data/val.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "COVSCAfadeb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (96824,)\n",
      "Cleaned Train Data Shape: (31279,)\n",
      "Validation Data Shape: (23409,)\n",
      "Test Data Shape: (23409,)\n",
      " \n",
      "Number of labels = 0 in train dataset as percentage: 1.97%\n",
      "Number of labels = 1 in train dataset as percentage: 7.79%\n",
      "Number of labels = 2 in train dataset as percentage: 10.33%\n",
      "Number of labels = 3 in train dataset as percentage: 9.54%\n",
      "Number of labels = 4 in train dataset as percentage: 2.67%\n",
      "Number of labels = -100 in train dataset as percentage: 67.69%\n",
      " \n",
      "Number of labels = 0 in val dataset as percentage: 4.52%\n",
      "Number of labels = 1 in val dataset as percentage: 17.47%\n",
      "Number of labels = 2 in val dataset as percentage: 50.61%\n",
      "Number of labels = 3 in val dataset as percentage: 21.33%\n",
      "Number of labels = 4 in val dataset as percentage: 6.08%\n",
      "Number of labels = -100 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# get all train data (labelled and unlabelled)\n",
    "X_train    = train_data['Phrase']\n",
    "y_train    = train_data['Sentiment']\n",
    "\n",
    "index_of_2_to_remove = np.random.choice(np.arange(y_train.size)[y_train == 2], np.arange(y_train.size)[y_train == 2].size - 10000, replace=False)\n",
    "index_of_2_to_remove.sort()\n",
    "X_train = X_train.drop(index_of_2_to_remove)\n",
    "y_train = y_train.drop(index_of_2_to_remove)\n",
    "train_data = train_data.drop(index_of_2_to_remove)\n",
    "\n",
    "# get only labelled train data\n",
    "mask = (y_train != -100)\n",
    "train_data_clean    = train_data[mask]\n",
    "X_train_clean    = X_train[mask]\n",
    "y_train_clean    = y_train[mask]\n",
    "\n",
    "# get val data\n",
    "X_val    = val_data['Phrase']\n",
    "y_val    = val_data['Sentiment']\n",
    "\n",
    "# get test data\n",
    "X_test     = test_data['Phrase']\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}\")\n",
    "print(f\"Cleaned Train Data Shape: {train_data_clean['Phrase'].shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"Number of labels = 0 in train dataset as percentage: {((y_train == 0).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in train dataset as percentage: {((y_train == 1).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in train dataset as percentage: {((y_train == 2).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in train dataset as percentage: {((y_train == 3).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in train dataset as percentage: {((y_train == 4).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = -100 in train dataset as percentage: {((y_train == -100).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_val == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_val == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_val == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_val == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_val == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = -100 in val dataset as percentage: {((y_val == -100).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that out of all the labelled data we have (train data), a lot of data points are assigned the label 2. This skew in our data is bound to cause inconsistencies in training down the line so we aim to keep only about 50% of the rows of label 2 (10000 are kept out of the total 22000 rows labelled 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xlccu-qCz18"
   },
   "source": [
    "# Define Preprocessing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "v5v2_Ro6ca5I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    #added substitutions\n",
    "\n",
    "    #***********added substitutions***********\n",
    "    # remove all the special characters\n",
    "    texter = re.sub(r'\\W', ' ', texter)\n",
    "    # remove all single characters\n",
    "    texter = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove single characters from the start\n",
    "    texter = re.sub(r'\\^[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove numbers\n",
    "    texter = re.sub(r'\\d+', ' ', texter)\n",
    "    # Converting to Lowercase\n",
    "    texter = texter.lower()\n",
    "    # Remove punctuation\n",
    "    texter = re.sub(r'[^\\w\\s]', ' ', texter)\n",
    "    # Remove parentheses\n",
    "    texter = re.sub(r'\\([^)]*\\)', ' ', texter)\n",
    "    # Remove single quotes\n",
    "    texter = re.sub(r'\\'', ' ', texter)\n",
    "    # Substituting multiple spaces with single space\n",
    "    texter = re.sub(r'\\s+', ' ', texter, flags=re.I)\n",
    "\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    for row in range(dataset.shape[0]):\n",
    "        dataset[row,0] = clean(dataset[row,0])\n",
    "    return dataset\n",
    "\n",
    "def tokenize_lexicon(texts):\n",
    "    return_texts = []\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append(nltk.word_tokenize(texts[i]))\n",
    "        return_texts[i] = nltk.pos_tag(return_texts[i])\n",
    "    return return_texts\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN\n",
    "\n",
    "def lemmatize_texts(texts):\n",
    "    return_texts = []\n",
    "    lemmer = nltk.stem.WordNetLemmatizer()\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append([])\n",
    "        for j in range(len(texts[i])):\n",
    "                return_texts[i].append(lemmer.lemmatize(texts[i][j][0], pos=get_wordnet_pos(texts[i][j][1])))\n",
    "    return return_texts\n",
    "\n",
    "def stem_texts(texts):\n",
    "    return_texts = []\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append([])\n",
    "        for j in range(len(texts[i])):\n",
    "                return_texts[i].append(ps.stem(texts[i][j][0]))\n",
    "    return return_texts\n",
    "\n",
    "\n",
    "def backtostring(texts):\n",
    "    return_texts = []\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append(\" \".join(texts[i]))\n",
    "    return return_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_XKPAT4grMt"
   },
   "source": [
    "# Preprocess using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "wWpMOdJ2uipq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def pre_process(data):\n",
    "    preproc_data = data.copy()\n",
    "    preproc_data = preproc_data.str.lower()\n",
    "    punctuation = string.punctuation\n",
    "    mapping = str.maketrans(\"\", \"\", punctuation)\n",
    "    preproc_data = preproc_data.str.translate(mapping)\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    preproc_data = preproc_data.apply(lambda text: ' '.join([word for word in text.split() if word.lower() not in stop_words]))\n",
    "    nltk.download('wordnet')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    preproc_data = preproc_data.apply(lambda text: ' '.join([lemmatizer.lemmatize(word) for word in text.split()]))\n",
    "    preproc_data = preproc_data.apply(lambda text: re.sub(r'@\\w+', '', re.sub(r'http\\S+|www\\S+', '', text)))\n",
    "    return preproc_data\n",
    "\n",
    "# get the preprocessed data\n",
    "X_train_preproc   = pre_process(X_train)\n",
    "X_train_clean_preproc   = pre_process(X_train_clean)\n",
    "X_val_preproc = pre_process(X_val)\n",
    "X_test_preproc = pre_process(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GhiuEjdumEO"
   },
   "source": [
    "Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "-ES4zksi-z2J"
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat([X_train_preproc, X_val_preproc, X_test_preproc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "sdBuYWZ1-knR"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_data = combined_data\n",
    "words = ' '.join(text_data).split()\n",
    "word_freq_dict = Counter(words)\n",
    "\n",
    "word_frequencies = list(word_freq_dict.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(word_frequencies, bins=55, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Word Frequency')\n",
    "plt.ylabel('Number of Words that show up X times')\n",
    "plt.title('Distribution of Word Frequencies')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "fD4ZzrPQuo7B"
   },
   "outputs": [],
   "source": [
    "def bag_of_word(data,  threshold_M):\n",
    "    vectorizer = CountVectorizer(binary=True, max_features= threshold_M)\n",
    "    vectorizer.fit(combined_data)\n",
    "    X = vectorizer.transform(data)\n",
    "    featurized_data = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "    return featurized_data\n",
    "\n",
    "# get the featurized data\n",
    "X_train   = bag_of_word(X_train_preproc, 500)\n",
    "X_train_clean = bag_of_word(X_train_clean_preproc, 500)\n",
    "X_val = bag_of_word(X_val_preproc, 500)\n",
    "X_test = bag_of_word(X_test_preproc, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actress</th>\n",
       "      <th>actually</th>\n",
       "      <th>adult</th>\n",
       "      <th>adventure</th>\n",
       "      <th>age</th>\n",
       "      <th>almost</th>\n",
       "      <th>...</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96824 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       act  acting  action  actor  actress  actually  adult  adventure  age  \\\n",
       "0        0       0       0      0        0         0      0          0    0   \n",
       "1        0       0       0      1        0         0      0          0    0   \n",
       "2        0       0       0      0        0         0      0          0    0   \n",
       "3        0       0       0      0        0         0      0          0    0   \n",
       "4        0       0       0      0        0         0      0          0    0   \n",
       "...    ...     ...     ...    ...      ...       ...    ...        ...  ...   \n",
       "96819    0       0       0      0        0         0      0          0    0   \n",
       "96820    0       0       0      0        0         0      0          0    0   \n",
       "96821    0       0       0      0        0         0      0          0    0   \n",
       "96822    0       0       0      0        0         0      0          0    0   \n",
       "96823    0       0       0      0        0         0      0          0    0   \n",
       "\n",
       "       almost  ...  worst  worth  would  writing  written  wrong  year  yet  \\\n",
       "0           0  ...      0      0      0        0        0      0     0    0   \n",
       "1           0  ...      0      0      0        0        0      0     0    0   \n",
       "2           0  ...      0      0      0        0        0      0     0    0   \n",
       "3           0  ...      0      0      0        0        0      0     0    0   \n",
       "4           0  ...      0      0      0        0        0      0     0    0   \n",
       "...       ...  ...    ...    ...    ...      ...      ...    ...   ...  ...   \n",
       "96819       0  ...      0      0      0        0        0      0     0    0   \n",
       "96820       0  ...      0      0      0        0        0      0     0    0   \n",
       "96821       0  ...      0      0      0        0        0      0     0    0   \n",
       "96822       0  ...      0      0      0        0        0      0     0    0   \n",
       "96823       0  ...      0      0      0        0        0      0     0    0   \n",
       "\n",
       "       york  young  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "96819     0      0  \n",
       "96820     0      0  \n",
       "96821     0      0  \n",
       "96822     0      0  \n",
       "96823     0      0  \n",
       "\n",
       "[96824 rows x 500 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6o6quWYA4dm"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "VSmj-gV0ES9I"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3)\n",
    "clf.fit(X_train_clean, y_train_clean)\n",
    "sk_y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "GwgerXc2HPeP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.49%\n",
      "Number of labels = 1 in val dataset as percentage: 14.34%\n",
      "Number of labels = 2 in val dataset as percentage: 60.71%\n",
      "Number of labels = 3 in val dataset as percentage: 23.00%\n",
      "Number of labels = 4 in val dataset as percentage: 1.47%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X71WprhUHBe_"
   },
   "source": [
    "Sklearn Linear SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "t8Zpe4FRF32u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47725233884403434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train_clean, y_train_clean)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "6wDYD96AGxom"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 3.02%\n",
      "Number of labels = 1 in val dataset as percentage: 23.64%\n",
      "Number of labels = 2 in val dataset as percentage: 49.56%\n",
      "Number of labels = 3 in val dataset as percentage: 20.81%\n",
      "Number of labels = 4 in val dataset as percentage: 2.97%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cache = X_train\n",
    "X_val_cache = X_val\n",
    "X_test_cache = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSQOZqupuKGO"
   },
   "source": [
    "# Preprocess the data using CountVectorizer, nltk stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "-4LDKgHgiMpa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43697,)\n",
      "(23409,)\n",
      "(23409,)\n",
      "(90515,)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.72 GiB for an array with shape (90515, 7000) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\laksh\\OneDrive\\Desktop\\USA\\cornell-tech\\aml\\midterm\\midterm_template.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdel\u001b[39;00m processed_texts\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdel\u001b[39;00m vectorizer\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m X_dense \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mtodense()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(X_dense\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdel\u001b[39;00m X\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\_base.py:946\u001b[0m, in \u001b[0;36mspmatrix.todense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtodense\u001b[39m(\u001b[39mself\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    917\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39m    Return a dense matrix representation of this matrix.\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[39m        `numpy.matrix` object that shares the same memory.\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ascontainer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoarray(order\u001b[39m=\u001b[39;49morder, out\u001b[39m=\u001b[39;49mout))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.72 GiB for an array with shape (90515, 7000) and data type int64"
     ]
    }
   ],
   "source": [
    "lemma = True\n",
    "\n",
    "# train set\n",
    "train = clean_dataset(np.array(train_data_clean))\n",
    "val = clean_dataset(np.array(val_data))\n",
    "test = clean_dataset(np.expand_dims(np.array(test_data[\"Phrase\"]), axis = 1))\n",
    "print(train[:,0].shape)\n",
    "print(val[:,0].shape)\n",
    "print(test[:,0].shape)\n",
    "print(np.concatenate((train[:,0], test[:,0], val[:,0])).shape)\n",
    "\n",
    "token_texts = tokenize_lexicon(np.concatenate((train[:,0], val[:,0], test[:,0])))\n",
    "\n",
    "del train\n",
    "del val\n",
    "del test\n",
    "\n",
    "if(lemma):\n",
    "    lemm_texts = lemmatize_texts(token_texts)\n",
    "else:\n",
    "    lemm_texts = stem_texts(token_texts)\n",
    "del token_texts\n",
    "processed_texts = backtostring(lemm_texts)\n",
    "del lemm_texts\n",
    "# matrix counts\n",
    "vectorizer = CountVectorizer(input='content', stop_words='english', min_df=3, max_features = 7000)\n",
    "X = vectorizer.fit_transform(processed_texts)\n",
    "del processed_texts\n",
    "del vectorizer\n",
    "X_dense = X.todense()\n",
    "print(X_dense.shape)\n",
    "del X\n",
    "\n",
    "# tfidf\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(np.array(X_dense))\n",
    "del X_dense\n",
    "X_data = (np.array(X_tfidf.todense()))\n",
    "print(\"X_data.shape: \", X_data.shape)\n",
    "\n",
    "X_train = X_data[:train_data_clean['Phrase'].shape[0]]\n",
    "X_val = X_data[train_data_clean['Phrase'].shape[0]:train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]]\n",
    "X_test = X_data[train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]:]\n",
    "del X_data\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_val.shape: \", X_val.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZyTz60oE2Ml"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuPqD9lShdPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5772566107052843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3) # tried 1,10,100,1e-3\n",
    "clf.fit(X_train, y_train_clean)\n",
    "sk_y = clf.predict(X_val)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# print(\"Feature Count \\n\",clf.feature_count_)\n",
    "# print(\"Class Log Prior \",clf.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, sk_y))\n",
    "# print(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5cV_v97hdPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 1.48%\n",
      "Number of labels = 1 in val dataset as percentage: 10.13%\n",
      "Number of labels = 2 in val dataset as percentage: 69.83%\n",
      "Number of labels = 3 in val dataset as percentage: 16.37%\n",
      "Number of labels = 4 in val dataset as percentage: 2.19%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yko5XY2ME3E2"
   },
   "source": [
    "Sklearn SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sY8LDnqghdPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5894314152676321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_clean)\n",
    "y_val_pred = clf_sgd.predict(X_val)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfoPr89LhdPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.30%\n",
      "Number of labels = 1 in val dataset as percentage: 0.63%\n",
      "Number of labels = 2 in val dataset as percentage: 90.08%\n",
      "Number of labels = 3 in val dataset as percentage: 9.00%\n",
      "Number of labels = 4 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_cache\n",
    "X_val = X_val_cache\n",
    "X_test_cache = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZRRGm7AFXTY"
   },
   "source": [
    "# Part 1: Now that you have your baseline numbers, run your (at least 2) unsupervised algorithms on the unlabelled portion of your train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "vhiW-YaRFfaA"
   },
   "outputs": [],
   "source": [
    "y_train == -100\n",
    "y_train[y_train == -100] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach for data augmentation\n",
    "We plan to implement three models for data augmentation. \n",
    "1. Firstly, K Nearest Neighbour classifier model which uses already provided labels to train itself. Then, when provided a data point, it classifies the provided data point into one of the 5 Sentiment values based on the 5 nearest neighbours of that point on the graph.\n",
    "\n",
    "2. Secondly, we will use LogisticRegression which is a simple yet powerful supervised learning technique where in the model is trained to plot a separator line that best divides data points with different labels.\n",
    "\n",
    "3. Lastly, we will use a RandomForest Classfier model where in classifcations from multiple decision trees are aggregated to arrive at the final label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train_clean, y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96824"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_numpy()[y_train == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# X_train[y_train == -100].to_numpy()\n",
    "unlabbeled_x = X_train.to_numpy()[y_train == -1]\n",
    "all_predicted_labels_KNN = neigh.predict(unlabbeled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65545,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3\n",
       "1         1\n",
       "2         1\n",
       "4         1\n",
       "5         2\n",
       "         ..\n",
       "109237    2\n",
       "109238    3\n",
       "109239    3\n",
       "109240    3\n",
       "109241    1\n",
       "Name: Sentiment, Length: 96824, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_complete = y_train\n",
    "y_train_complete[y_train == -1] = all_predicted_labels_KNN\n",
    "y_train_complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression model trained with Tfidf vectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Reload the training data\n",
    "train_data_lr = pd.read_csv('./data/train.csv')\n",
    "y_train_lr = train_data_lr['Sentiment'].values\n",
    "\n",
    "# Initialize and transform using the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf_lr = tfidf_vectorizer.fit_transform(train_data_lr['Phrase'])\n",
    "\n",
    "# Separate the labeled and unlabeled data\n",
    "X_val_tfidf_lr = tfidf_vectorizer.transform(val_data['Phrase'])\n",
    "X_train_labeled_lr = X_train_tfidf_lr[y_train_lr != -100]\n",
    "y_train_labeled_lr = y_train_lr[y_train_lr != -100]\n",
    "X_train_unlabeled_lr = X_train_tfidf_lr[y_train_lr == -100]\n",
    "\n",
    "# Instantiate the Logistic Regression model with multi_class parameter\n",
    "logreg = LogisticRegression(multi_class='multinomial', max_iter=1000, solver='lbfgs')\n",
    "\n",
    "# Train the Logistic Regression model on the labeled data\n",
    "logreg.fit(X_train_labeled_lr, y_train_labeled_lr)\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels_for_unlabeled_lr = logreg.predict(X_train_unlabeled_lr)\n",
    "\n",
    "# Replace the -100 values in y_train with the predicted labels\n",
    "y_train_lr[y_train_lr == -100] = predicted_labels_for_unlabeled_lr\n",
    "\n",
    "# Re-train the Logistic Regression model on the entire training data (labeled + newly labeled)\n",
    "logreg.fit(X_train_tfidf_lr, y_train_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model trained with Tfidf vectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43697, 5000), (65545, 5000))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_data_rf = pd.read_csv('./data/train.csv')\n",
    "val_data_rf = pd.read_csv('./data/val.csv')\n",
    "test_data_rf = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Extract labels and phrases\n",
    "y_train_rf = train_data_rf['Sentiment'].values\n",
    "X_train_rf = train_data_rf['Phrase']\n",
    "X_val_rf = val_data_rf['Phrase']\n",
    "\n",
    "# Initialize and transform using the TF-IDF vectorizer\n",
    "tfidf_vectorizer_rf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf_rf = tfidf_vectorizer_rf.fit_transform(X_train_rf)\n",
    "X_val_tfidf_rf = tfidf_vectorizer_rf.transform(X_val_rf)\n",
    "X_test_tfidf_rf = tfidf_vectorizer_rf.transform(test_data_rf['Phrase'])\n",
    "\n",
    "# Separate the labeled and unlabeled data\n",
    "X_train_labeled_rf = X_train_tfidf_rf[y_train_rf != -100]\n",
    "y_train_labeled_rf = y_train_rf[y_train_rf != -100]\n",
    "X_train_unlabeled_rf = X_train_tfidf_rf[y_train_rf == -100]\n",
    "\n",
    "X_train_labeled_rf.shape, X_train_unlabeled_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    69.074682\n",
       "3    14.986650\n",
       "1    10.592723\n",
       "4     3.223739\n",
       "0     2.122206\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the Random Forest classifier on the labeled data\n",
    "rf_classifier.fit(X_train_labeled_rf, y_train_labeled_rf)\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels_for_unlabeled_rf = rf_classifier.predict(X_train_unlabeled_rf)\n",
    "\n",
    "# Replace the -100 values in y_train_rf with the predicted labels\n",
    "y_train_rf[y_train_rf == -100] = predicted_labels_for_unlabeled_rf\n",
    "\n",
    "# Check the distribution of the newly predicted labels\n",
    "predicted_label_distribution = pd.Series(predicted_labels_for_unlabeled_rf).value_counts(normalize=True) * 100\n",
    "predicted_label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnvyM4VvFj-A"
   },
   "source": [
    "# Part 2: With your newly augmented dataset, re-run your supervised algorithms. How do the performance values change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "L6QLp6NJFu-s"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3)\n",
    "clf.fit(X_train, y_train_complete)\n",
    "sk_y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.76%\n",
      "Number of labels = 1 in val dataset as percentage: 9.14%\n",
      "Number of labels = 2 in val dataset as percentage: 78.11%\n",
      "Number of labels = 3 in val dataset as percentage: 11.25%\n",
      "Number of labels = 4 in val dataset as percentage: 0.74%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn Linear SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5312913836558588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_complete)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 1.92%\n",
      "Number of labels = 1 in val dataset as percentage: 13.32%\n",
      "Number of labels = 2 in val dataset as percentage: 65.35%\n",
      "Number of labels = 3 in val dataset as percentage: 18.38%\n",
      "Number of labels = 4 in val dataset as percentage: 1.03%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23409,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model on test data\n",
    "y_test_pred_SGD = clf_sgd.predict(X_test)\n",
    "y_test_pred_SGD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_SGD = pd.DataFrame()\n",
    "submission_SGD[\"PhraseId\"] = test_data[\"PhraseId\"]\n",
    "submission_SGD[\"Sentiment\"] = y_test_pred_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_SGD.to_csv(\"./target_sgd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the label distributions for y_val and y_val_predictions_lr in the desired format\n",
    "\n",
    "def print_label_distribution(y_data, dataset_name):\n",
    "    total_count = len(y_data)\n",
    "    for i in range(5):  # As there are 5 labels\n",
    "        label_count = (y_data == i).sum()\n",
    "        print(f\"Number of labels = {i} in {dataset_name} dataset as percentage: {(label_count / total_count) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5981032936050237\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset - regression\n",
    "y_val_predictions_lr = logreg.predict(X_val_tfidf_lr)\n",
    "accuracy_lr = accuracy_score(y_val, y_val_predictions_lr)\n",
    "classification_rep_lr = classification_report(y_val, y_val_predictions_lr)\n",
    "\n",
    "print('Accuracy:', accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dataset (y_val) Distribution:\n",
      "Number of labels = 0 in val dataset as percentage: 4.52%\n",
      "Number of labels = 1 in val dataset as percentage: 17.47%\n",
      "Number of labels = 2 in val dataset as percentage: 50.61%\n",
      "Number of labels = 3 in val dataset as percentage: 21.33%\n",
      "Number of labels = 4 in val dataset as percentage: 6.08%\n",
      "\n",
      "Predictions on Validation Dataset (y_val_predictions_lr) Distribution:\n",
      "Number of labels = 0 in xval (predictions) dataset as percentage: 0.60%\n",
      "Number of labels = 1 in xval (predictions) dataset as percentage: 9.30%\n",
      "Number of labels = 2 in xval (predictions) dataset as percentage: 72.90%\n",
      "Number of labels = 3 in xval (predictions) dataset as percentage: 15.60%\n",
      "Number of labels = 4 in xval (predictions) dataset as percentage: 1.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Dataset (y_val) Distribution:\")\n",
    "print_label_distribution(y_val, \"val\")\n",
    "\n",
    "print(\"\\nPredictions on Validation Dataset (y_val_predictions_lr) Distribution:\")\n",
    "print_label_distribution(y_val_predictions_lr, \"xval (predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23409x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 127429 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating Tfidf-Logistic Regression model on test data\n",
    "X_test_tfidf_lr = tfidf_vectorizer.transform(test_data[\"Phrase\"])\n",
    "X_test_tfidf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions_lr = logreg.predict(X_test_tfidf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23409,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predictions_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lr = pd.DataFrame()\n",
    "submission_lr[\"PhraseId\"] = test_data[\"PhraseId\"]\n",
    "submission_lr[\"Sentiment\"] = y_test_predictions_lr\n",
    "submission_lr.to_csv(\"./target_lr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5897731641676278"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(multi_class='multinomial', max_iter=1000, solver='lbfgs')\n",
    "\n",
    "# Train the model on the augmented dataset\n",
    "logreg.fit(X_train_tfidf_rf, y_train_rf)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_predictions_rf = logreg.predict(X_val_tfidf_rf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(val_data_rf['Sentiment'], y_val_predictions_rf)\n",
    "\n",
    "accuracy_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions_rf = logreg.predict(X_test_tfidf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rf = pd.DataFrame()\n",
    "submission_rf[\"PhraseId\"] = test_data[\"PhraseId\"]\n",
    "submission_rf[\"Sentiment\"] = y_test_predictions_rf\n",
    "submission_rf.to_csv(\"./target_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
