{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aQoMk--DCfN"
   },
   "source": [
    "This template notebook should serve as a guide for how to load and manipulate the dataset, and the different preprocessing methods you may choose to implement (you are welcome to try any others outside of what is provided here). This code should be treated as pseudo-code - and you may have to debug this code to get it working adequately.\n",
    "\n",
    "In this notebook, we only access the labeled portion of the training dataset, and directly run/train/fit supervised methods. e.g., Multinomial Naive Bayes and Linear SGD classifiers (linear SGD [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html] implements regularized linear models with stochastic gradient descent, e.g., by choosing loss=‘log_loss’, you obtain a logistic regression classifier), on only this labeled portion of the training dataset. The performance values you get from running this experiment will serve as your baseline.\n",
    "\n",
    "Once you have these baseline numbers for the configuration of preprocessing and supervised methods you choose (ideally at least 2 preprocessing methods and also at least 2 supervised methods), you can now begin working on Part 1: i.e. using unsupervised learning methods to automate adding labels to the unlabelled portion of the train dataset. The goal is to see if adding these newly labeled data examples to the train set will improve the baseline numbers you obtained (i.e. Part 2: running the supervised methods you chose for the baseline on the newly augmented dataset and reporting the performance on this augmented dataset).\n",
    "\n",
    "Lastly, please note that there is a class imbalance in the train, test, and val sets. You will have to incorporate an approach to deal with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0DBGcZfs0FJ"
   },
   "outputs": [],
   "source": [
    "# e.g. if using google colab import drive, uncomment lines below\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LX0ia6JVtFjr"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as sk_OLS\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.semi_supervised import LabelPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD0dQabauB7z"
   },
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "uRBDrBxYtBbk"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "val_data = pd.read_csv(\"./data/val.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "COVSCAfadeb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (109242,)\n",
      "Cleaned Train Data Shape: (43697,)\n",
      "Validation Data Shape: (23409,)\n",
      "Test Data Shape: (23409,)\n",
      " \n",
      "Number of labels = 0 in train dataset as percentage: 1.75%\n",
      "Number of labels = 1 in train dataset as percentage: 6.91%\n",
      "Number of labels = 2 in train dataset as percentage: 20.52%\n",
      "Number of labels = 3 in train dataset as percentage: 8.46%\n",
      "Number of labels = 4 in train dataset as percentage: 2.37%\n",
      "Number of labels = -100 in train dataset as percentage: 60.00%\n",
      " \n",
      "Number of labels = 0 in val dataset as percentage: 4.52%\n",
      "Number of labels = 1 in val dataset as percentage: 17.47%\n",
      "Number of labels = 2 in val dataset as percentage: 50.61%\n",
      "Number of labels = 3 in val dataset as percentage: 21.33%\n",
      "Number of labels = 4 in val dataset as percentage: 6.08%\n",
      "Number of labels = -100 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# get all train data (labelled and unlabelled)\n",
    "X_train    = train_data['Phrase']\n",
    "y_train    = train_data['Sentiment']\n",
    "\n",
    "# get only labelled train data\n",
    "mask = (y_train != -100)\n",
    "train_data_clean    = train_data[mask]\n",
    "X_train_clean    = X_train[mask]\n",
    "y_train_clean    = y_train[mask]\n",
    "\n",
    "# get val data\n",
    "X_val    = val_data['Phrase']\n",
    "y_val    = val_data['Sentiment']\n",
    "\n",
    "# get test data\n",
    "X_test     = test_data['Phrase']\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}\")\n",
    "print(f\"Cleaned Train Data Shape: {train_data_clean['Phrase'].shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"Number of labels = 0 in train dataset as percentage: {((y_train == 0).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in train dataset as percentage: {((y_train == 1).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in train dataset as percentage: {((y_train == 2).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in train dataset as percentage: {((y_train == 3).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in train dataset as percentage: {((y_train == 4).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = -100 in train dataset as percentage: {((y_train == -100).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_val == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_val == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_val == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_val == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_val == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = -100 in val dataset as percentage: {((y_val == -100).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xlccu-qCz18"
   },
   "source": [
    "# Define Preprocessing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "v5v2_Ro6ca5I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    #added substitutions\n",
    "\n",
    "    #***********added substitutions***********\n",
    "    # remove all the special characters\n",
    "    texter = re.sub(r'\\W', ' ', texter)\n",
    "    # remove all single characters\n",
    "    texter = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove single characters from the start\n",
    "    texter = re.sub(r'\\^[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove numbers\n",
    "    texter = re.sub(r'\\d+', ' ', texter)\n",
    "    # Converting to Lowercase\n",
    "    texter = texter.lower()\n",
    "    # Remove punctuation\n",
    "    texter = re.sub(r'[^\\w\\s]', ' ', texter)\n",
    "    # Remove parentheses\n",
    "    texter = re.sub(r'\\([^)]*\\)', ' ', texter)\n",
    "    # Remove single quotes\n",
    "    texter = re.sub(r'\\'', ' ', texter)\n",
    "    # Substituting multiple spaces with single space\n",
    "    texter = re.sub(r'\\s+', ' ', texter, flags=re.I)\n",
    "\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    for row in range(dataset.shape[0]):\n",
    "        dataset[row,0] = clean(dataset[row,0])\n",
    "    return dataset\n",
    "\n",
    "def tokenize_lexicon(texts):\n",
    "    return_texts = []\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append(nltk.word_tokenize(texts[i]))\n",
    "        return_texts[i] = nltk.pos_tag(return_texts[i])\n",
    "    return return_texts\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN\n",
    "\n",
    "def lemmatize_texts(texts):\n",
    "    return_texts = []\n",
    "    lemmer = nltk.stem.WordNetLemmatizer()\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append([])\n",
    "        for j in range(len(texts[i])):\n",
    "                return_texts[i].append(lemmer.lemmatize(texts[i][j][0], pos=get_wordnet_pos(texts[i][j][1])))\n",
    "    return return_texts\n",
    "\n",
    "def stem_texts(texts):\n",
    "    return_texts = []\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append([])\n",
    "        for j in range(len(texts[i])):\n",
    "                return_texts[i].append(ps.stem(texts[i][j][0]))\n",
    "    return return_texts\n",
    "\n",
    "\n",
    "def backtostring(texts):\n",
    "    return_texts = []\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append(\" \".join(texts[i]))\n",
    "    return return_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_XKPAT4grMt"
   },
   "source": [
    "# Preprocess using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "wWpMOdJ2uipq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def pre_process(data):\n",
    "    preproc_data = data.copy()\n",
    "    preproc_data = preproc_data.str.lower()\n",
    "    punctuation = string.punctuation\n",
    "    mapping = str.maketrans(\"\", \"\", punctuation)\n",
    "    preproc_data = preproc_data.str.translate(mapping)\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    preproc_data = preproc_data.apply(lambda text: ' '.join([word for word in text.split() if word.lower() not in stop_words]))\n",
    "    nltk.download('wordnet')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    preproc_data = preproc_data.apply(lambda text: ' '.join([lemmatizer.lemmatize(word) for word in text.split()]))\n",
    "    preproc_data = preproc_data.apply(lambda text: re.sub(r'@\\w+', '', re.sub(r'http\\S+|www\\S+', '', text)))\n",
    "    return preproc_data\n",
    "\n",
    "# get the preprocessed data\n",
    "X_train_preproc   = pre_process(X_train)\n",
    "X_train_clean_preproc   = pre_process(X_train_clean)\n",
    "X_val_preproc = pre_process(X_val)\n",
    "X_test_preproc = pre_process(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GhiuEjdumEO"
   },
   "source": [
    "Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-ES4zksi-z2J"
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat([X_train_preproc, X_val_preproc, X_test_preproc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "sdBuYWZ1-knR"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_data = combined_data\n",
    "words = ' '.join(text_data).split()\n",
    "word_freq_dict = Counter(words)\n",
    "\n",
    "word_frequencies = list(word_freq_dict.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(word_frequencies, bins=55, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Word Frequency')\n",
    "plt.ylabel('Number of Words that show up X times')\n",
    "plt.title('Distribution of Word Frequencies')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "fD4ZzrPQuo7B"
   },
   "outputs": [],
   "source": [
    "def bag_of_word(data,  threshold_M):\n",
    "    vectorizer = CountVectorizer(binary=True, max_features= threshold_M)\n",
    "    vectorizer.fit(combined_data)\n",
    "    X = vectorizer.transform(data)\n",
    "    featurized_data = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "    return featurized_data\n",
    "\n",
    "# get the featurized data\n",
    "X_train   = bag_of_word(X_train_preproc, 1500)\n",
    "X_train_clean = bag_of_word(X_train_clean_preproc, 1500)\n",
    "X_val = bag_of_word(X_val_preproc, 1500)\n",
    "X_test = bag_of_word(X_test_preproc, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>2002</th>\n",
       "      <th>70</th>\n",
       "      <th>90</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorbing</th>\n",
       "      <th>abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wry</th>\n",
       "      <th>yarn</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109238</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109240</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109242 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10  20  2002  70  90  ability  able  absolutely  absorbing  abstract  \\\n",
       "0        0   0     0   0   0        0     0           0          0         0   \n",
       "1        0   0     0   0   0        0     0           0          0         0   \n",
       "2        0   0     0   0   0        0     0           0          0         0   \n",
       "3        0   0     0   0   0        0     0           0          0         0   \n",
       "4        0   0     0   0   0        0     0           0          0         0   \n",
       "...     ..  ..   ...  ..  ..      ...   ...         ...        ...       ...   \n",
       "109237   0   0     0   0   0        0     0           0          0         0   \n",
       "109238   0   0     0   0   0        0     0           0          0         0   \n",
       "109239   0   0     0   0   0        0     0           0          0         0   \n",
       "109240   0   0     0   0   0        0     0           0          0         0   \n",
       "109241   0   0     0   0   0        0     0           0          0         0   \n",
       "\n",
       "        ...  writing  written  wrong  wry  yarn  year  yet  york  young  zone  \n",
       "0       ...        0        0      0    0     0     0    0     0      0     0  \n",
       "1       ...        0        0      0    0     0     0    0     0      0     0  \n",
       "2       ...        0        0      0    0     0     0    0     0      0     0  \n",
       "3       ...        0        0      0    0     0     0    0     0      0     0  \n",
       "4       ...        0        0      0    0     0     0    0     0      0     0  \n",
       "...     ...      ...      ...    ...  ...   ...   ...  ...   ...    ...   ...  \n",
       "109237  ...        0        0      0    0     0     0    0     0      0     0  \n",
       "109238  ...        0        0      0    0     0     0    0     0      0     0  \n",
       "109239  ...        0        0      0    0     0     0    0     0      0     0  \n",
       "109240  ...        0        0      0    0     0     0    0     0      0     0  \n",
       "109241  ...        0        0      0    0     0     0    0     0      0     0  \n",
       "\n",
       "[109242 rows x 1500 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6o6quWYA4dm"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "VSmj-gV0ES9I"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3)\n",
    "clf.fit(X_train_clean, y_train_clean)\n",
    "sk_y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "GwgerXc2HPeP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 1.27%\n",
      "Number of labels = 1 in val dataset as percentage: 7.24%\n",
      "Number of labels = 2 in val dataset as percentage: 76.72%\n",
      "Number of labels = 3 in val dataset as percentage: 12.29%\n",
      "Number of labels = 4 in val dataset as percentage: 2.47%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X71WprhUHBe_"
   },
   "source": [
    "Sklearn Linear SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "t8Zpe4FRF32u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.579435259942757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train_clean, y_train_clean)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "6wDYD96AGxom"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 2.05%\n",
      "Number of labels = 1 in val dataset as percentage: 6.40%\n",
      "Number of labels = 2 in val dataset as percentage: 72.74%\n",
      "Number of labels = 3 in val dataset as percentage: 15.18%\n",
      "Number of labels = 4 in val dataset as percentage: 3.64%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSQOZqupuKGO"
   },
   "source": [
    "# Preprocess the data using CountVectorizer, nltk stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "-4LDKgHgiMpa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43697,)\n",
      "(23409,)\n",
      "(23409,)\n",
      "(90515,)\n",
      "(90515, 7000)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.72 GiB for an array with shape (90515, 7000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\laksh\\OneDrive\\Desktop\\USA\\cornell-tech\\aml\\midterm\\midterm_template.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X30sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# tfidf\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X30sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m tfidf_vectorizer \u001b[39m=\u001b[39m TfidfTransformer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X30sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m X_tfidf \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39;49mfit_transform(np\u001b[39m.\u001b[39;49marray(X_dense))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X30sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mdel\u001b[39;00m X_dense\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X30sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m X_data \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39marray(X_tfidf\u001b[39m.\u001b[39mtodense()))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\feature_extraction\\text.py:1704\u001b[0m, in \u001b[0;36mTfidfTransformer.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1688\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Transform a count matrix to a tf or tf-idf representation.\u001b[39;00m\n\u001b[0;32m   1689\u001b[0m \n\u001b[0;32m   1690\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1704\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1705\u001b[0m         X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES, copy\u001b[39m=\u001b[39;49mcopy, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m   1708\u001b[0m         X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.72 GiB for an array with shape (90515, 7000) and data type float64"
     ]
    }
   ],
   "source": [
    "lemma = True\n",
    "\n",
    "# train set\n",
    "train = clean_dataset(np.array(train_data_clean))\n",
    "val = clean_dataset(np.array(val_data))\n",
    "test = clean_dataset(np.expand_dims(np.array(test_data[\"Phrase\"]), axis = 1))\n",
    "print(train[:,0].shape)\n",
    "print(val[:,0].shape)\n",
    "print(test[:,0].shape)\n",
    "print(np.concatenate((train[:,0], test[:,0], val[:,0])).shape)\n",
    "\n",
    "token_texts = tokenize_lexicon(np.concatenate((train[:,0], val[:,0], test[:,0])))\n",
    "\n",
    "del train\n",
    "del val\n",
    "del test\n",
    "\n",
    "if(lemma):\n",
    "    lemm_texts = lemmatize_texts(token_texts)\n",
    "else:\n",
    "    lemm_texts = stem_texts(token_texts)\n",
    "del token_texts\n",
    "processed_texts = backtostring(lemm_texts)\n",
    "del lemm_texts\n",
    "# matrix counts\n",
    "vectorizer = CountVectorizer(input='content', stop_words='english', min_df=3, max_features = 7000)\n",
    "X = vectorizer.fit_transform(processed_texts)\n",
    "del processed_texts\n",
    "del vectorizer\n",
    "X_dense = X.todense()\n",
    "print(X_dense.shape)\n",
    "del X\n",
    "\n",
    "# tfidf\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(np.array(X_dense))\n",
    "del X_dense\n",
    "X_data = (np.array(X_tfidf.todense()))\n",
    "print(\"X_data.shape: \", X_data.shape)\n",
    "\n",
    "X_train = X_data[:train_data_clean['Phrase'].shape[0]]\n",
    "X_val = X_data[train_data_clean['Phrase'].shape[0]:train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]]\n",
    "X_test = X_data[train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]:]\n",
    "del X_data\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_val.shape: \", X_val.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZyTz60oE2Ml"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nuPqD9lShdPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5772566107052843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3) # tried 1,10,100,1e-3\n",
    "clf.fit(X_train, y_train_clean)\n",
    "sk_y = clf.predict(X_val)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# print(\"Feature Count \\n\",clf.feature_count_)\n",
    "# print(\"Class Log Prior \",clf.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, sk_y))\n",
    "# print(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e5cV_v97hdPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 1.48%\n",
      "Number of labels = 1 in val dataset as percentage: 10.13%\n",
      "Number of labels = 2 in val dataset as percentage: 69.83%\n",
      "Number of labels = 3 in val dataset as percentage: 16.37%\n",
      "Number of labels = 4 in val dataset as percentage: 2.19%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yko5XY2ME3E2"
   },
   "source": [
    "Sklearn SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sY8LDnqghdPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5894314152676321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_clean)\n",
    "y_val_pred = clf_sgd.predict(X_val)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KfoPr89LhdPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.30%\n",
      "Number of labels = 1 in val dataset as percentage: 0.63%\n",
      "Number of labels = 2 in val dataset as percentage: 90.08%\n",
      "Number of labels = 3 in val dataset as percentage: 9.00%\n",
      "Number of labels = 4 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWn4WbbPdKMY"
   },
   "source": [
    "# Preprocess using Glove\n",
    "\n",
    "Download the \"glove.6B.300d.txt\" embedding file from [this link](http://nlp.uoregon.edu/download/embeddings/). WARNING: THIS IS A 1GB DOWNLOAD.\n",
    "\n",
    "The following pseudo-code is erroneous/buggy -> you will have to debug this code to genertae your feature vectors based on the GLoVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "BuN9Qd4IcR5n"
   },
   "outputs": [],
   "source": [
    "glove = {}\n",
    "dimension_of_glove = 300\n",
    "with open(\"./data/glove.6B.300d.txt\", 'rb') as f: # if 'r' fails with unicode error, please use 'rb'\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0].decode('utf-8')\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "pzoXVJSxcR5n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "# Number of words\n",
    "print(len(glove.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "NXz2xVVAcR5n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# Embedding length\n",
    "for i in glove.values():\n",
    "    print(len(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "xe_wD39JcR5o"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_keywords_as_list(df):\n",
    "    # Preprocess and get the keywords as a list of lists\n",
    "    raw_list_keywords = []\n",
    "    phrases = list(df[\"Phrase\"])\n",
    "    # print(phrases)\n",
    "    # print(type(phrases))\n",
    "    for idx, text in enumerate(phrases):\n",
    "        if idx == 0:\n",
    "            print(text)\n",
    "        # Each entry in \"keywords\" is a list of keywords. But they are stored as strings and not as a list.\n",
    "        # We need to convert this string to a list.\n",
    "        texter = text.lower()\n",
    "        # Remove single quotes\n",
    "        texter = re.sub(r'\\'', '', texter)\n",
    "        # Remove the [] at the start and end. Split entries by \", \"\n",
    "        text_as_list = texter.strip('[]').split(\", \")\n",
    "        raw_list_keywords.append(text_as_list)\n",
    "        if idx == 0:\n",
    "            print(raw_list_keywords)\n",
    "    return raw_list_keywords\n",
    "\n",
    "def clean_list_keywords(raw_lkeys):\n",
    "    cleaned_list_keywords = []\n",
    "    for lkeys in raw_lkeys:\n",
    "        cleaned_list_keywords.append([key for key in lkeys if key in glove.keys()])\n",
    "    return cleaned_list_keywords\n",
    "\n",
    "def normalize_vector(vec):\n",
    "    return vec / np.linalg.norm(vec,ord=2)\n",
    "\n",
    "def get_feature_list(cleaned_lkeys, glove_model):\n",
    "    feat_list = []\n",
    "    for lkeys in cleaned_lkeys:\n",
    "        # Zero initial value since we will average them glove_model values for all the keywords\n",
    "        # We use 'the' as an example key to get the number of dims.\n",
    "        # 'the' is a very common word and would be there in any training corpus.\n",
    "        rep_glove_vec = np.zeros(len(glove_model['the']))\n",
    "        for key in lkeys:\n",
    "            rep_glove_vec += glove_model[key]\n",
    "        rep_glove_vec /= len(lkeys)\n",
    "\n",
    "        # feat_list.append(normalize_vector(rep_glove_vec))\n",
    "        feat_list.append(rep_glove_vec)\n",
    "    return np.array(feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "nfNuBc4icR5o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fincher 's\n",
      "[['fincher s']]\n",
      "This is the sort of low-grade dreck that usually goes straight to video -- with a lousy script , inept direction , pathetic acting , poorly dubbed dialogue and murky cinematography , complete with visible boom mikes .\n",
      "[['this is the sort of low-grade dreck that usually goes straight to video -- with a lousy script ', 'inept direction ', 'pathetic acting ', 'poorly dubbed dialogue and murky cinematography ', 'complete with visible boom mikes .']]\n",
      "the magnificent Jackie Chan\n",
      "[['the magnificent jackie chan']]\n"
     ]
    }
   ],
   "source": [
    "# init_kws = get_keywords_as_list(train_data_clean)\n",
    "# init_kws[0]\n",
    "train_kws = clean_list_keywords(get_keywords_as_list(train_data_clean))\n",
    "val_kws = clean_list_keywords(get_keywords_as_list(val_data))\n",
    "test_kws = clean_list_keywords(get_keywords_as_list(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "PTXvUmZScR5o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8992\\3435481906.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  rep_glove_vec /= len(lkeys)\n"
     ]
    }
   ],
   "source": [
    "X_train = get_feature_list(train_kws, glove)\n",
    "X_val = get_feature_list(val_kws, glove)\n",
    "X_test = get_feature_list(test_kws, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FGyNJnnecbGh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43697, 300)\n",
      "(23409, 300)\n",
      "(23409, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fj_7lOBXE7nG"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "JXgbOEmmcbI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076252723311547\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = HistGradientBoostingClassifier() # tried 1,10,100,1e-3\n",
    "clf.fit(X_train, y_train_clean)\n",
    "sk_y = clf.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf.feature_count_)\n",
    "# print(\"Class Log Prior \",clf.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, sk_y))\n",
    "# print(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "BB1j_5SNcbK9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.04%\n",
      "Number of labels = 1 in val dataset as percentage: 0.32%\n",
      "Number of labels = 2 in val dataset as percentage: 99.28%\n",
      "Number of labels = 3 in val dataset as percentage: 0.34%\n",
      "Number of labels = 4 in val dataset as percentage: 0.02%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr6P_V4EE7nH"
   },
   "source": [
    "Sklearn SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "NcqDR65WcbNS"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\laksh\\OneDrive\\Desktop\\USA\\cornell-tech\\aml\\midterm\\midterm_template.ipynb Cell 41\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf_sgd \u001b[39m=\u001b[39m SGDClassifier(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhinge\u001b[39m\u001b[39m'\u001b[39m, penalty\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m,alpha\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m clf_sgd\u001b[39m.\u001b[39;49mfit(X_train, y_train_clean)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf_sgd\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(\"Feature Count \\n\",clf_sgd.feature_count_)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:907\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \n\u001b[0;32m    880\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39m    Returns an instance of self.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_more_validate_params()\n\u001b[1;32m--> 907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    908\u001b[0m     X,\n\u001b[0;32m    909\u001b[0m     y,\n\u001b[0;32m    910\u001b[0m     alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[0;32m    911\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[0;32m    912\u001b[0m     loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[0;32m    913\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[0;32m    914\u001b[0m     coef_init\u001b[39m=\u001b[39;49mcoef_init,\n\u001b[0;32m    915\u001b[0m     intercept_init\u001b[39m=\u001b[39;49mintercept_init,\n\u001b[0;32m    916\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    917\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:694\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[39m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    695\u001b[0m     X,\n\u001b[0;32m    696\u001b[0m     y,\n\u001b[0;32m    697\u001b[0m     alpha,\n\u001b[0;32m    698\u001b[0m     C,\n\u001b[0;32m    699\u001b[0m     loss,\n\u001b[0;32m    700\u001b[0m     learning_rate,\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    702\u001b[0m     classes,\n\u001b[0;32m    703\u001b[0m     sample_weight,\n\u001b[0;32m    704\u001b[0m     coef_init,\n\u001b[0;32m    705\u001b[0m     intercept_init,\n\u001b[0;32m    706\u001b[0m )\n\u001b[0;32m    708\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    709\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    710\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39m>\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[0;32m    711\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[0;32m    712\u001b[0m ):\n\u001b[0;32m    713\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    714\u001b[0m         (\n\u001b[0;32m    715\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMaximum number of iteration reached before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    720\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:586\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_partial_fit\u001b[39m(\n\u001b[0;32m    572\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    573\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m     intercept_init,\n\u001b[0;32m    584\u001b[0m ):\n\u001b[0;32m    585\u001b[0m     first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclasses_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 586\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    587\u001b[0m         X,\n\u001b[0;32m    588\u001b[0m         y,\n\u001b[0;32m    589\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    590\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m    591\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    592\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    593\u001b[0m         reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[0;32m    594\u001b[0m     )\n\u001b[0;32m    596\u001b[0m     n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    598\u001b[0m     _check_partial_fit_first_call(\u001b[39mself\u001b[39m, classes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nSGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_clean)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "4aZdRV6pzd2s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Number of labels = 0 in val dataset as percentage: 0.30%\n",
      "Number of labels = 1 in val dataset as percentage: 0.63%\n",
      "Number of labels = 2 in val dataset as percentage: 90.08%\n",
      "Number of labels = 3 in val dataset as percentage: 9.00%\n",
      "Number of labels = 4 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print((y_pred == 2).all())\n",
    "\n",
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZRRGm7AFXTY"
   },
   "source": [
    "# Part 1: Now that you have your baseline numbers, run your (at least 2) unsupervised algorithms on the unlabelled portion of your train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "vhiW-YaRFfaA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_28768\\503741236.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train[y_train == -100] = -1\n"
     ]
    }
   ],
   "source": [
    "y_train == -100\n",
    "y_train[y_train == -100] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.22 GiB for an array with shape (109242, 1500) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\laksh\\OneDrive\\Desktop\\USA\\cornell-tech\\aml\\midterm\\midterm_template.ipynb Cell 47\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m label_prop_model \u001b[39m=\u001b[39m LabelPropagation()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#Y100sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m label_prop_model\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49mto_numpy(), y_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:484\u001b[0m, in \u001b[0;36mLabelPropagation.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    466\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit a semi-supervised label propagation model to X.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \n\u001b[0;32m    468\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:268\u001b[0m, in \u001b[0;36mBaseLabelPropagation.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    265\u001b[0m check_classification_targets(y)\n\u001b[0;32m    267\u001b[0m \u001b[39m# actual graph construction (implementations should override this)\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m graph_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_graph()\n\u001b[0;32m    270\u001b[0m \u001b[39m# label construction\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[39m# construct a categorical distribution for classification only\u001b[39;00m\n\u001b[0;32m    272\u001b[0m classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:457\u001b[0m, in \u001b[0;36mLabelPropagation._build_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mknn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_fit \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m affinity_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_kernel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_)\n\u001b[0;32m    458\u001b[0m normalizer \u001b[39m=\u001b[39m affinity_matrix\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    459\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39misspmatrix(affinity_matrix):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:147\u001b[0m, in \u001b[0;36mBaseLabelPropagation._get_kernel\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m         \u001b[39mreturn\u001b[39;00m rbf_kernel(X, X, gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgamma)\n\u001b[0;32m    148\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m         \u001b[39mreturn\u001b[39;00m rbf_kernel(X, y, gamma\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\pairwise.py:1474\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1438\u001b[0m     {\n\u001b[0;32m   1439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1448\u001b[0m )\n\u001b[0;32m   1449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrbf_kernel\u001b[39m(X, Y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, gamma\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1450\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the rbf (gaussian) kernel between X and Y.\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m \n\u001b[0;32m   1452\u001b[0m \u001b[39m        K(x, y) = exp(-gamma ||x-y||^2)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[39m        The RBF kernel.\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1474\u001b[0m     X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1475\u001b[0m     \u001b[39mif\u001b[39;00m gamma \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1476\u001b[0m         gamma \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\pairwise.py:156\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    153\u001b[0m     dtype \u001b[39m=\u001b[39m dtype_float\n\u001b[0;32m    155\u001b[0m \u001b[39mif\u001b[39;00m Y \u001b[39mis\u001b[39;00m X \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    157\u001b[0m         X,\n\u001b[0;32m    158\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    159\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    160\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    161\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    162\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    166\u001b[0m         X,\n\u001b[0;32m    167\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    172\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.22 GiB for an array with shape (109242, 1500) and data type float64"
     ]
    }
   ],
   "source": [
    "label_prop_model = LabelPropagation()\n",
    "label_prop_model.fit(X_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train_clean, y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# X_train[y_train == -100].to_numpy()\n",
    "unlabbeled_x = X_train[y_train == -1].to_numpy()\n",
    "all_predicted_labels = neigh.predict(unlabbeled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_28768\\399752770.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train_complete[y_train == -1] = all_predicted_labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         3\n",
       "3         2\n",
       "4         1\n",
       "         ..\n",
       "109237    2\n",
       "109238    2\n",
       "109239    3\n",
       "109240    3\n",
       "109241    1\n",
       "Name: Sentiment, Length: 109242, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_complete = y_train\n",
    "y_train_complete[y_train == -1] = all_predicted_labels\n",
    "y_train_complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnvyM4VvFj-A"
   },
   "source": [
    "# Part 2: With your newly augmented dataset, re-run your supervised algorithms. How do the performance values change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "L6QLp6NJFu-s"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3)\n",
    "clf.fit(X_train, y_train_complete)\n",
    "sk_y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.94%\n",
      "Number of labels = 1 in val dataset as percentage: 3.77%\n",
      "Number of labels = 2 in val dataset as percentage: 88.51%\n",
      "Number of labels = 3 in val dataset as percentage: 5.72%\n",
      "Number of labels = 4 in val dataset as percentage: 1.06%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn Linear SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5539749668930753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_complete)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 1.79%\n",
      "Number of labels = 1 in val dataset as percentage: 3.69%\n",
      "Number of labels = 2 in val dataset as percentage: 84.52%\n",
      "Number of labels = 3 in val dataset as percentage: 8.57%\n",
      "Number of labels = 4 in val dataset as percentage: 1.42%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
