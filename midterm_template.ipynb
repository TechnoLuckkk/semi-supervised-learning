{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aQoMk--DCfN"
   },
   "source": [
    "This template notebook should serve as a guide for how to load and manipulate the dataset, and the different preprocessing methods you may choose to implement (you are welcome to try any others outside of what is provided here). This code should be treated as pseudo-code - and you may have to debug this code to get it working adequately.\n",
    "\n",
    "In this notebook, we only access the labeled portion of the training dataset, and directly run/train/fit supervised methods. e.g., Multinomial Naive Bayes and Linear SGD classifiers (linear SGD [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html] implements regularized linear models with stochastic gradient descent, e.g., by choosing loss=‘log_loss’, you obtain a logistic regression classifier), on only this labeled portion of the training dataset. The performance values you get from running this experiment will serve as your baseline.\n",
    "\n",
    "Once you have these baseline numbers for the configuration of preprocessing and supervised methods you choose (ideally at least 2 preprocessing methods and also at least 2 supervised methods), you can now begin working on Part 1: i.e. using unsupervised learning methods to automate adding labels to the unlabelled portion of the train dataset. The goal is to see if adding these newly labeled data examples to the train set will improve the baseline numbers you obtained (i.e. Part 2: running the supervised methods you chose for the baseline on the newly augmented dataset and reporting the performance on this augmented dataset).\n",
    "\n",
    "Lastly, please note that there is a class imbalance in the train, test, and val sets. You will have to incorporate an approach to deal with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0DBGcZfs0FJ"
   },
   "outputs": [],
   "source": [
    "# e.g. if using google colab import drive, uncomment lines below\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LX0ia6JVtFjr"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as sk_OLS\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.semi_supervised import LabelPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD0dQabauB7z"
   },
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uRBDrBxYtBbk"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "val_data = pd.read_csv(\"./data/val.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "COVSCAfadeb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (96824,)\n",
      "Cleaned Train Data Shape: (31279,)\n",
      "Validation Data Shape: (23409,)\n",
      "Test Data Shape: (23409,)\n",
      " \n",
      "Number of labels = 0 in train dataset as percentage: 1.97%\n",
      "Number of labels = 1 in train dataset as percentage: 7.79%\n",
      "Number of labels = 2 in train dataset as percentage: 10.33%\n",
      "Number of labels = 3 in train dataset as percentage: 9.54%\n",
      "Number of labels = 4 in train dataset as percentage: 2.67%\n",
      "Number of labels = -100 in train dataset as percentage: 67.69%\n",
      " \n",
      "Number of labels = 0 in val dataset as percentage: 4.52%\n",
      "Number of labels = 1 in val dataset as percentage: 17.47%\n",
      "Number of labels = 2 in val dataset as percentage: 50.61%\n",
      "Number of labels = 3 in val dataset as percentage: 21.33%\n",
      "Number of labels = 4 in val dataset as percentage: 6.08%\n",
      "Number of labels = -100 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# get all train data (labelled and unlabelled)\n",
    "X_train    = train_data['Phrase']\n",
    "y_train    = train_data['Sentiment']\n",
    "\n",
    "index_of_2_to_remove = np.random.choice(np.arange(y_train.size)[y_train == 2], np.arange(y_train.size)[y_train == 2].size - 10000, replace=False)\n",
    "index_of_2_to_remove.sort()\n",
    "X_train = X_train.drop(index_of_2_to_remove)\n",
    "y_train = y_train.drop(index_of_2_to_remove)\n",
    "train_data = train_data.drop(index_of_2_to_remove)\n",
    "\n",
    "# get only labelled train data\n",
    "mask = (y_train != -100)\n",
    "train_data_clean    = train_data[mask]\n",
    "X_train_clean    = X_train[mask]\n",
    "y_train_clean    = y_train[mask]\n",
    "\n",
    "# get val data\n",
    "X_val    = val_data['Phrase']\n",
    "y_val    = val_data['Sentiment']\n",
    "\n",
    "# get test data\n",
    "X_test     = test_data['Phrase']\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}\")\n",
    "print(f\"Cleaned Train Data Shape: {train_data_clean['Phrase'].shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"Number of labels = 0 in train dataset as percentage: {((y_train == 0).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in train dataset as percentage: {((y_train == 1).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in train dataset as percentage: {((y_train == 2).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in train dataset as percentage: {((y_train == 3).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in train dataset as percentage: {((y_train == 4).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = -100 in train dataset as percentage: {((y_train == -100).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_val == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_val == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_val == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_val == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_val == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = -100 in val dataset as percentage: {((y_val == -100).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that out of all the labelled data we have (train data), a lot of data points are assigned the label 2. This skew in our data is bound to cause inconsistencies in training down the line so we aim to keep only about 50% of the rows of label 2 (10000 are kept out of the total 22000 rows labelled 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xlccu-qCz18"
   },
   "source": [
    "# Define Preprocessing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "v5v2_Ro6ca5I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    #added substitutions\n",
    "\n",
    "    #***********added substitutions***********\n",
    "    # remove all the special characters\n",
    "    texter = re.sub(r'\\W', ' ', texter)\n",
    "    # remove all single characters\n",
    "    texter = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove single characters from the start\n",
    "    texter = re.sub(r'\\^[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove numbers\n",
    "    texter = re.sub(r'\\d+', ' ', texter)\n",
    "    # Converting to Lowercase\n",
    "    texter = texter.lower()\n",
    "    # Remove punctuation\n",
    "    texter = re.sub(r'[^\\w\\s]', ' ', texter)\n",
    "    # Remove parentheses\n",
    "    texter = re.sub(r'\\([^)]*\\)', ' ', texter)\n",
    "    # Remove single quotes\n",
    "    texter = re.sub(r'\\'', ' ', texter)\n",
    "    # Substituting multiple spaces with single space\n",
    "    texter = re.sub(r'\\s+', ' ', texter, flags=re.I)\n",
    "\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    for row in range(dataset.shape[0]):\n",
    "        dataset[row,0] = clean(dataset[row,0])\n",
    "    return dataset\n",
    "\n",
    "def tokenize_lexicon(texts):\n",
    "    return_texts = []\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append(nltk.word_tokenize(texts[i]))\n",
    "        return_texts[i] = nltk.pos_tag(return_texts[i])\n",
    "    return return_texts\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN\n",
    "\n",
    "def lemmatize_texts(texts):\n",
    "    return_texts = []\n",
    "    lemmer = nltk.stem.WordNetLemmatizer()\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append([])\n",
    "        for j in range(len(texts[i])):\n",
    "                return_texts[i].append(lemmer.lemmatize(texts[i][j][0], pos=get_wordnet_pos(texts[i][j][1])))\n",
    "    return return_texts\n",
    "\n",
    "def stem_texts(texts):\n",
    "    return_texts = []\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append([])\n",
    "        for j in range(len(texts[i])):\n",
    "                return_texts[i].append(ps.stem(texts[i][j][0]))\n",
    "    return return_texts\n",
    "\n",
    "\n",
    "def backtostring(texts):\n",
    "    return_texts = []\n",
    "    for i in range(len(texts)):\n",
    "        return_texts.append(\" \".join(texts[i]))\n",
    "    return return_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_XKPAT4grMt"
   },
   "source": [
    "# Preprocess using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wWpMOdJ2uipq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def pre_process(data):\n",
    "    preproc_data = data.copy()\n",
    "    preproc_data = preproc_data.str.lower()\n",
    "    punctuation = string.punctuation\n",
    "    mapping = str.maketrans(\"\", \"\", punctuation)\n",
    "    preproc_data = preproc_data.str.translate(mapping)\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    preproc_data = preproc_data.apply(lambda text: ' '.join([word for word in text.split() if word.lower() not in stop_words]))\n",
    "    nltk.download('wordnet')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    preproc_data = preproc_data.apply(lambda text: ' '.join([lemmatizer.lemmatize(word) for word in text.split()]))\n",
    "    preproc_data = preproc_data.apply(lambda text: re.sub(r'@\\w+', '', re.sub(r'http\\S+|www\\S+', '', text)))\n",
    "    return preproc_data\n",
    "\n",
    "# get the preprocessed data\n",
    "X_train_preproc   = pre_process(X_train)\n",
    "X_train_clean_preproc   = pre_process(X_train_clean)\n",
    "X_val_preproc = pre_process(X_val)\n",
    "X_test_preproc = pre_process(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GhiuEjdumEO"
   },
   "source": [
    "Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-ES4zksi-z2J"
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat([X_train_preproc, X_val_preproc, X_test_preproc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "sdBuYWZ1-knR"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_data = combined_data\n",
    "words = ' '.join(text_data).split()\n",
    "word_freq_dict = Counter(words)\n",
    "\n",
    "word_frequencies = list(word_freq_dict.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(word_frequencies, bins=55, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Word Frequency')\n",
    "plt.ylabel('Number of Words that show up X times')\n",
    "plt.title('Distribution of Word Frequencies')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fD4ZzrPQuo7B"
   },
   "outputs": [],
   "source": [
    "def bag_of_word(data,  threshold_M):\n",
    "    vectorizer = CountVectorizer(binary=True, max_features= threshold_M)\n",
    "    vectorizer.fit(combined_data)\n",
    "    X = vectorizer.transform(data)\n",
    "    featurized_data = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "    return featurized_data\n",
    "\n",
    "# get the featurized data\n",
    "X_train   = bag_of_word(X_train_preproc, 500)\n",
    "X_train_clean = bag_of_word(X_train_clean_preproc, 500)\n",
    "X_val = bag_of_word(X_val_preproc, 500)\n",
    "X_test = bag_of_word(X_test_preproc, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actress</th>\n",
       "      <th>actually</th>\n",
       "      <th>adult</th>\n",
       "      <th>adventure</th>\n",
       "      <th>age</th>\n",
       "      <th>almost</th>\n",
       "      <th>...</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96824 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       act  acting  action  actor  actress  actually  adult  adventure  age  \\\n",
       "0        0       0       0      0        0         0      0          0    0   \n",
       "1        0       0       0      1        0         0      0          0    0   \n",
       "2        0       0       0      0        0         0      0          0    0   \n",
       "3        0       0       0      0        0         0      0          0    0   \n",
       "4        0       0       0      0        0         0      0          0    0   \n",
       "...    ...     ...     ...    ...      ...       ...    ...        ...  ...   \n",
       "96819    0       0       0      0        0         0      0          0    0   \n",
       "96820    0       0       0      0        0         0      0          0    0   \n",
       "96821    0       0       0      0        0         0      0          0    0   \n",
       "96822    0       0       0      0        0         0      0          0    0   \n",
       "96823    0       0       0      0        0         0      0          0    0   \n",
       "\n",
       "       almost  ...  worst  worth  would  writing  written  wrong  year  yet  \\\n",
       "0           0  ...      0      0      0        0        0      0     0    0   \n",
       "1           0  ...      0      0      0        0        0      0     0    0   \n",
       "2           0  ...      0      0      0        0        0      0     0    0   \n",
       "3           0  ...      0      0      0        0        0      0     0    0   \n",
       "4           0  ...      0      0      0        0        0      0     0    0   \n",
       "...       ...  ...    ...    ...    ...      ...      ...    ...   ...  ...   \n",
       "96819       0  ...      0      0      0        0        0      0     0    0   \n",
       "96820       0  ...      0      0      0        0        0      0     0    0   \n",
       "96821       0  ...      0      0      0        0        0      0     0    0   \n",
       "96822       0  ...      0      0      0        0        0      0     0    0   \n",
       "96823       0  ...      0      0      0        0        0      0     0    0   \n",
       "\n",
       "       york  young  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "96819     0      0  \n",
       "96820     0      0  \n",
       "96821     0      0  \n",
       "96822     0      0  \n",
       "96823     0      0  \n",
       "\n",
       "[96824 rows x 500 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6o6quWYA4dm"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VSmj-gV0ES9I"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3)\n",
    "clf.fit(X_train_clean, y_train_clean)\n",
    "sk_y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "GwgerXc2HPeP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.47%\n",
      "Number of labels = 1 in val dataset as percentage: 14.69%\n",
      "Number of labels = 2 in val dataset as percentage: 61.13%\n",
      "Number of labels = 3 in val dataset as percentage: 22.21%\n",
      "Number of labels = 4 in val dataset as percentage: 1.50%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X71WprhUHBe_"
   },
   "source": [
    "Sklearn Linear SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "t8Zpe4FRF32u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5068563373061643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train_clean, y_train_clean)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "6wDYD96AGxom"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 1.57%\n",
      "Number of labels = 1 in val dataset as percentage: 15.36%\n",
      "Number of labels = 2 in val dataset as percentage: 54.28%\n",
      "Number of labels = 3 in val dataset as percentage: 24.55%\n",
      "Number of labels = 4 in val dataset as percentage: 4.24%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cache = X_train\n",
    "X_val_cache = X_val\n",
    "X_test_cache = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSQOZqupuKGO"
   },
   "source": [
    "# Preprocess the data using CountVectorizer, nltk stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "-4LDKgHgiMpa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43697,)\n",
      "(23409,)\n",
      "(23409,)\n",
      "(90515,)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.72 GiB for an array with shape (90515, 7000) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\laksh\\OneDrive\\Desktop\\USA\\cornell-tech\\aml\\midterm\\midterm_template.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdel\u001b[39;00m processed_texts\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdel\u001b[39;00m vectorizer\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m X_dense \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mtodense()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(X_dense\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdel\u001b[39;00m X\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\_base.py:946\u001b[0m, in \u001b[0;36mspmatrix.todense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtodense\u001b[39m(\u001b[39mself\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    917\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39m    Return a dense matrix representation of this matrix.\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[39m        `numpy.matrix` object that shares the same memory.\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ascontainer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoarray(order\u001b[39m=\u001b[39;49morder, out\u001b[39m=\u001b[39;49mout))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.72 GiB for an array with shape (90515, 7000) and data type int64"
     ]
    }
   ],
   "source": [
    "lemma = True\n",
    "\n",
    "# train set\n",
    "train = clean_dataset(np.array(train_data_clean))\n",
    "val = clean_dataset(np.array(val_data))\n",
    "test = clean_dataset(np.expand_dims(np.array(test_data[\"Phrase\"]), axis = 1))\n",
    "print(train[:,0].shape)\n",
    "print(val[:,0].shape)\n",
    "print(test[:,0].shape)\n",
    "print(np.concatenate((train[:,0], test[:,0], val[:,0])).shape)\n",
    "\n",
    "token_texts = tokenize_lexicon(np.concatenate((train[:,0], val[:,0], test[:,0])))\n",
    "\n",
    "del train\n",
    "del val\n",
    "del test\n",
    "\n",
    "if(lemma):\n",
    "    lemm_texts = lemmatize_texts(token_texts)\n",
    "else:\n",
    "    lemm_texts = stem_texts(token_texts)\n",
    "del token_texts\n",
    "processed_texts = backtostring(lemm_texts)\n",
    "del lemm_texts\n",
    "# matrix counts\n",
    "vectorizer = CountVectorizer(input='content', stop_words='english', min_df=3, max_features = 7000)\n",
    "X = vectorizer.fit_transform(processed_texts)\n",
    "del processed_texts\n",
    "del vectorizer\n",
    "X_dense = X.todense()\n",
    "print(X_dense.shape)\n",
    "del X\n",
    "\n",
    "# tfidf\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(np.array(X_dense))\n",
    "del X_dense\n",
    "X_data = (np.array(X_tfidf.todense()))\n",
    "print(\"X_data.shape: \", X_data.shape)\n",
    "\n",
    "X_train = X_data[:train_data_clean['Phrase'].shape[0]]\n",
    "X_val = X_data[train_data_clean['Phrase'].shape[0]:train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]]\n",
    "X_test = X_data[train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]:]\n",
    "del X_data\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_val.shape: \", X_val.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZyTz60oE2Ml"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuPqD9lShdPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5772566107052843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3) # tried 1,10,100,1e-3\n",
    "clf.fit(X_train, y_train_clean)\n",
    "sk_y = clf.predict(X_val)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# print(\"Feature Count \\n\",clf.feature_count_)\n",
    "# print(\"Class Log Prior \",clf.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, sk_y))\n",
    "# print(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5cV_v97hdPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 1.48%\n",
      "Number of labels = 1 in val dataset as percentage: 10.13%\n",
      "Number of labels = 2 in val dataset as percentage: 69.83%\n",
      "Number of labels = 3 in val dataset as percentage: 16.37%\n",
      "Number of labels = 4 in val dataset as percentage: 2.19%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yko5XY2ME3E2"
   },
   "source": [
    "Sklearn SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sY8LDnqghdPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5894314152676321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_clean)\n",
    "y_val_pred = clf_sgd.predict(X_val)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfoPr89LhdPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.30%\n",
      "Number of labels = 1 in val dataset as percentage: 0.63%\n",
      "Number of labels = 2 in val dataset as percentage: 90.08%\n",
      "Number of labels = 3 in val dataset as percentage: 9.00%\n",
      "Number of labels = 4 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWn4WbbPdKMY"
   },
   "source": [
    "# Preprocess using Glove\n",
    "\n",
    "Download the \"glove.6B.300d.txt\" embedding file from [this link](http://nlp.uoregon.edu/download/embeddings/). WARNING: THIS IS A 1GB DOWNLOAD.\n",
    "\n",
    "The following pseudo-code is erroneous/buggy -> you will have to debug this code to genertae your feature vectors based on the GLoVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuN9Qd4IcR5n"
   },
   "outputs": [],
   "source": [
    "glove = {}\n",
    "dimension_of_glove = 300\n",
    "with open(\"./data/glove.6B.300d.txt\", 'rb') as f: # if 'r' fails with unicode error, please use 'rb'\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0].decode('utf-8')\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzoXVJSxcR5n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "# Number of words\n",
    "print(len(glove.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXz2xVVAcR5n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# Embedding length\n",
    "for i in glove.values():\n",
    "    print(len(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xe_wD39JcR5o"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_keywords_as_list(df):\n",
    "    # Preprocess and get the keywords as a list of lists\n",
    "    raw_list_keywords = []\n",
    "    phrases = list(df[\"Phrase\"])\n",
    "    # print(phrases)\n",
    "    # print(type(phrases))\n",
    "    for idx, text in enumerate(phrases):\n",
    "        if idx == 0:\n",
    "            print(text)\n",
    "        # Each entry in \"keywords\" is a list of keywords. But they are stored as strings and not as a list.\n",
    "        # We need to convert this string to a list.\n",
    "        texter = text.lower()\n",
    "        # Remove single quotes\n",
    "        texter = re.sub(r'\\'', '', texter)\n",
    "        # Remove the [] at the start and end. Split entries by \", \"\n",
    "        text_as_list = texter.strip('[]').split(\", \")\n",
    "        raw_list_keywords.append(text_as_list)\n",
    "        if idx == 0:\n",
    "            print(raw_list_keywords)\n",
    "    return raw_list_keywords\n",
    "\n",
    "def clean_list_keywords(raw_lkeys):\n",
    "    cleaned_list_keywords = []\n",
    "    for lkeys in raw_lkeys:\n",
    "        cleaned_list_keywords.append([key for key in lkeys if key in glove.keys()])\n",
    "    return cleaned_list_keywords\n",
    "\n",
    "def normalize_vector(vec):\n",
    "    return vec / np.linalg.norm(vec,ord=2)\n",
    "\n",
    "def get_feature_list(cleaned_lkeys, glove_model):\n",
    "    feat_list = []\n",
    "    for lkeys in cleaned_lkeys:\n",
    "        # Zero initial value since we will average them glove_model values for all the keywords\n",
    "        # We use 'the' as an example key to get the number of dims.\n",
    "        # 'the' is a very common word and would be there in any training corpus.\n",
    "        rep_glove_vec = np.zeros(len(glove_model['the']))\n",
    "        for key in lkeys:\n",
    "            rep_glove_vec += glove_model[key]\n",
    "        rep_glove_vec /= len(lkeys)\n",
    "\n",
    "        # feat_list.append(normalize_vector(rep_glove_vec))\n",
    "        feat_list.append(rep_glove_vec)\n",
    "    return np.array(feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfNuBc4icR5o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fincher 's\n",
      "[['fincher s']]\n",
      "This is the sort of low-grade dreck that usually goes straight to video -- with a lousy script , inept direction , pathetic acting , poorly dubbed dialogue and murky cinematography , complete with visible boom mikes .\n",
      "[['this is the sort of low-grade dreck that usually goes straight to video -- with a lousy script ', 'inept direction ', 'pathetic acting ', 'poorly dubbed dialogue and murky cinematography ', 'complete with visible boom mikes .']]\n",
      "the magnificent Jackie Chan\n",
      "[['the magnificent jackie chan']]\n"
     ]
    }
   ],
   "source": [
    "# init_kws = get_keywords_as_list(train_data_clean)\n",
    "# init_kws[0]\n",
    "train_kws = clean_list_keywords(get_keywords_as_list(train_data_clean))\n",
    "val_kws = clean_list_keywords(get_keywords_as_list(val_data))\n",
    "test_kws = clean_list_keywords(get_keywords_as_list(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTXvUmZScR5o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8992\\3435481906.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  rep_glove_vec /= len(lkeys)\n"
     ]
    }
   ],
   "source": [
    "X_train = get_feature_list(train_kws, glove)\n",
    "X_val = get_feature_list(val_kws, glove)\n",
    "X_test = get_feature_list(test_kws, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGyNJnnecbGh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43697, 300)\n",
      "(23409, 300)\n",
      "(23409, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fj_7lOBXE7nG"
   },
   "source": [
    "Sklearn Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXgbOEmmcbI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076252723311547\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = HistGradientBoostingClassifier() # tried 1,10,100,1e-3\n",
    "clf.fit(X_train, y_train_clean)\n",
    "sk_y = clf.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf.feature_count_)\n",
    "# print(\"Class Log Prior \",clf.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, sk_y))\n",
    "# print(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB1j_5SNcbK9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.04%\n",
      "Number of labels = 1 in val dataset as percentage: 0.32%\n",
      "Number of labels = 2 in val dataset as percentage: 99.28%\n",
      "Number of labels = 3 in val dataset as percentage: 0.34%\n",
      "Number of labels = 4 in val dataset as percentage: 0.02%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr6P_V4EE7nH"
   },
   "source": [
    "Sklearn SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NcqDR65WcbNS"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\laksh\\OneDrive\\Desktop\\USA\\cornell-tech\\aml\\midterm\\midterm_template.ipynb Cell 41\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf_sgd \u001b[39m=\u001b[39m SGDClassifier(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhinge\u001b[39m\u001b[39m'\u001b[39m, penalty\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m,alpha\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m clf_sgd\u001b[39m.\u001b[39;49mfit(X_train, y_train_clean)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf_sgd\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(\"Feature Count \\n\",clf_sgd.feature_count_)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/laksh/OneDrive/Desktop/USA/cornell-tech/aml/midterm/midterm_template.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:907\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \n\u001b[0;32m    880\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39m    Returns an instance of self.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_more_validate_params()\n\u001b[1;32m--> 907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    908\u001b[0m     X,\n\u001b[0;32m    909\u001b[0m     y,\n\u001b[0;32m    910\u001b[0m     alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[0;32m    911\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[0;32m    912\u001b[0m     loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[0;32m    913\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[0;32m    914\u001b[0m     coef_init\u001b[39m=\u001b[39;49mcoef_init,\n\u001b[0;32m    915\u001b[0m     intercept_init\u001b[39m=\u001b[39;49mintercept_init,\n\u001b[0;32m    916\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    917\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:694\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[39m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    695\u001b[0m     X,\n\u001b[0;32m    696\u001b[0m     y,\n\u001b[0;32m    697\u001b[0m     alpha,\n\u001b[0;32m    698\u001b[0m     C,\n\u001b[0;32m    699\u001b[0m     loss,\n\u001b[0;32m    700\u001b[0m     learning_rate,\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    702\u001b[0m     classes,\n\u001b[0;32m    703\u001b[0m     sample_weight,\n\u001b[0;32m    704\u001b[0m     coef_init,\n\u001b[0;32m    705\u001b[0m     intercept_init,\n\u001b[0;32m    706\u001b[0m )\n\u001b[0;32m    708\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    709\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    710\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39m>\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[0;32m    711\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[0;32m    712\u001b[0m ):\n\u001b[0;32m    713\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    714\u001b[0m         (\n\u001b[0;32m    715\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMaximum number of iteration reached before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    720\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:586\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_partial_fit\u001b[39m(\n\u001b[0;32m    572\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    573\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m     intercept_init,\n\u001b[0;32m    584\u001b[0m ):\n\u001b[0;32m    585\u001b[0m     first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclasses_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 586\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    587\u001b[0m         X,\n\u001b[0;32m    588\u001b[0m         y,\n\u001b[0;32m    589\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    590\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m    591\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    592\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    593\u001b[0m         reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[0;32m    594\u001b[0m     )\n\u001b[0;32m    596\u001b[0m     n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    598\u001b[0m     _check_partial_fit_first_call(\u001b[39mself\u001b[39m, classes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nSGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_clean)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aZdRV6pzd2s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Number of labels = 0 in val dataset as percentage: 0.30%\n",
      "Number of labels = 1 in val dataset as percentage: 0.63%\n",
      "Number of labels = 2 in val dataset as percentage: 90.08%\n",
      "Number of labels = 3 in val dataset as percentage: 9.00%\n",
      "Number of labels = 4 in val dataset as percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print((y_pred == 2).all())\n",
    "\n",
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_cache\n",
    "X_val = X_val_cache\n",
    "X_test_cache = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZRRGm7AFXTY"
   },
   "source": [
    "# Part 1: Now that you have your baseline numbers, run your (at least 2) unsupervised algorithms on the unlabelled portion of your train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "vhiW-YaRFfaA"
   },
   "outputs": [],
   "source": [
    "y_train == -100\n",
    "y_train[y_train == -100] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train_clean, y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96824"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65545, 500)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_numpy()[y_train == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# X_train[y_train == -100].to_numpy()\n",
    "unlabbeled_x = X_train.to_numpy()[y_train == -1]\n",
    "all_predicted_labels_KNN = neigh.predict(unlabbeled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3\n",
       "1         3\n",
       "2         1\n",
       "4         1\n",
       "5         2\n",
       "         ..\n",
       "109237    1\n",
       "109238    2\n",
       "109239    3\n",
       "109240    3\n",
       "109241    3\n",
       "Name: Sentiment, Length: 96824, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_complete = y_train\n",
    "y_train_complete[y_train == -1] = all_predicted_labels_KNN\n",
    "y_train_complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Reload the training data\n",
    "train_data_lr = pd.read_csv('./data/train.csv')\n",
    "y_train_lr = train_data_lr['Sentiment'].values\n",
    "\n",
    "# Initialize and transform using the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf_lr = tfidf_vectorizer.fit_transform(train_data_lr['Phrase'])\n",
    "\n",
    "# Separate the labeled and unlabeled data\n",
    "X_val_tfidf_lr = tfidf_vectorizer.transform(val_data['Phrase'])\n",
    "X_train_labeled_lr = X_train_tfidf_lr[y_train_lr != -100]\n",
    "y_train_labeled_lr = y_train_lr[y_train_lr != -100]\n",
    "X_train_unlabeled_lr = X_train_tfidf_lr[y_train_lr == -100]\n",
    "\n",
    "# Instantiate the Logistic Regression model with multi_class parameter\n",
    "logreg = LogisticRegression(multi_class='multinomial', max_iter=1000, solver='lbfgs')\n",
    "\n",
    "# Train the Logistic Regression model on the labeled data\n",
    "logreg.fit(X_train_labeled_lr, y_train_labeled_lr)\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels_for_unlabeled_lr = logreg.predict(X_train_unlabeled_lr)\n",
    "\n",
    "# Replace the -100 values in y_train with the predicted labels\n",
    "y_train_lr[y_train_lr == -100] = predicted_labels_for_unlabeled_lr\n",
    "\n",
    "# Re-train the Logistic Regression model on the entire training data (labeled + newly labeled)\n",
    "logreg.fit(X_train_tfidf_lr, y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data_rf = pd.read_csv('train.csv')\n",
    "val_data_rf = pd.read_csv('val.csv')\n",
    "test_data_rf = pd.read_csv('test.csv')\n",
    "\n",
    "# Extract labels and phrases\n",
    "y_train_rf = train_data_rf['Sentiment'].values\n",
    "X_train_rf = train_data_rf['Phrase']\n",
    "X_val_rf = val_data_rf['Phrase']\n",
    "\n",
    "# Initialize and transform using the TF-IDF vectorizer\n",
    "tfidf_vectorizer_rf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf_rf = tfidf_vectorizer_rf.fit_transform(X_train_rf)\n",
    "X_val_tfidf_rf = tfidf_vectorizer_rf.transform(X_val_rf)\n",
    "X_test_tfidf_rf = tfidf_vectorizer_rf.transform(test_data_rf['Phrase'])\n",
    "\n",
    "# Separate the labeled and unlabeled data\n",
    "X_train_labeled_rf = X_train_tfidf_rf[y_train_rf != -100]\n",
    "y_train_labeled_rf = y_train_rf[y_train_rf != -100]\n",
    "X_train_unlabeled_rf = X_train_tfidf_rf[y_train_rf == -100]\n",
    "\n",
    "X_train_labeled_rf.shape, X_train_unlabeled_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the Random Forest classifier on the labeled data\n",
    "rf_classifier.fit(X_train_labeled_rf, y_train_labeled_rf)\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels_for_unlabeled_rf = rf_classifier.predict(X_train_unlabeled_rf)\n",
    "\n",
    "# Replace the -100 values in y_train_rf with the predicted labels\n",
    "y_train_rf[y_train_rf == -100] = predicted_labels_for_unlabeled_rf\n",
    "\n",
    "# Check the distribution of the newly predicted labels\n",
    "predicted_label_distribution = pd.Series(predicted_labels_for_unlabeled_rf).value_counts(normalize=True) * 100\n",
    "predicted_label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnvyM4VvFj-A"
   },
   "source": [
    "# Part 2: With your newly augmented dataset, re-run your supervised algorithms. How do the performance values change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "L6QLp6NJFu-s"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB(alpha=1e-3)\n",
    "clf.fit(X_train, y_train_complete)\n",
    "sk_y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.29%\n",
      "Number of labels = 1 in val dataset as percentage: 66.47%\n",
      "Number of labels = 2 in val dataset as percentage: 18.20%\n",
      "Number of labels = 3 in val dataset as percentage: 14.21%\n",
      "Number of labels = 4 in val dataset as percentage: 0.82%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn Linear SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.2876244179589047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
    "clf_sgd.fit(X_train, y_train_complete)\n",
    "y_pred = clf_sgd.predict(X_val)\n",
    "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
    "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
    "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
    "# print(clf_sgd.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 0 in val dataset as percentage: 0.97%\n",
      "Number of labels = 1 in val dataset as percentage: 59.18%\n",
      "Number of labels = 2 in val dataset as percentage: 17.88%\n",
      "Number of labels = 3 in val dataset as percentage: 19.88%\n",
      "Number of labels = 4 in val dataset as percentage: 2.09%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
    "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23409,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model on test data\n",
    "y_test_pred_SGD = clf_sgd.predict(X_test)\n",
    "y_test_pred_SGD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_SGD = pd.DataFrame()\n",
    "submission_SGD[\"PhraseId\"] = test_data[\"PhraseId\"]\n",
    "submission_SGD[\"Sentiment\"] = y_test_pred_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_SGD.to_csv(\"./target_sgd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the label distributions for y_val and y_val_predictions_lr in the desired format\n",
    "\n",
    "def print_label_distribution(y_data, dataset_name):\n",
    "    total_count = len(y_data)\n",
    "    for i in range(5):  # As there are 5 labels\n",
    "        label_count = (y_data == i).sum()\n",
    "        print(f\"Number of labels = {i} in {dataset_name} dataset as percentage: {(label_count / total_count) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5981032936050237\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset - regression\n",
    "y_val_predictions_lr = logreg.predict(X_val_tfidf_lr)\n",
    "accuracy_lr = accuracy_score(y_val, y_val_predictions_lr)\n",
    "classification_rep_lr = classification_report(y_val, y_val_predictions_lr)\n",
    "\n",
    "print('Accuracy:', accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dataset (y_val) Distribution:\n",
      "Number of labels = 0 in val dataset as percentage: 4.52%\n",
      "Number of labels = 1 in val dataset as percentage: 17.47%\n",
      "Number of labels = 2 in val dataset as percentage: 50.61%\n",
      "Number of labels = 3 in val dataset as percentage: 21.33%\n",
      "Number of labels = 4 in val dataset as percentage: 6.08%\n",
      "\n",
      "Predictions on Validation Dataset (y_val_predictions_lr) Distribution:\n",
      "Number of labels = 0 in xval (predictions) dataset as percentage: 0.60%\n",
      "Number of labels = 1 in xval (predictions) dataset as percentage: 9.30%\n",
      "Number of labels = 2 in xval (predictions) dataset as percentage: 72.90%\n",
      "Number of labels = 3 in xval (predictions) dataset as percentage: 15.60%\n",
      "Number of labels = 4 in xval (predictions) dataset as percentage: 1.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Dataset (y_val) Distribution:\")\n",
    "print_label_distribution(y_val, \"val\")\n",
    "\n",
    "print(\"\\nPredictions on Validation Dataset (y_val_predictions_lr) Distribution:\")\n",
    "print_label_distribution(y_val_predictions_lr, \"xval (predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23409x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 127429 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating Tfidf-Logistic Regression model on test data\n",
    "X_test_tfidf_lr = tfidf_vectorizer.transform(test_data[\"Phrase\"])\n",
    "X_test_tfidf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions_lr = logreg.predict(X_test_tfidf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23409,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predictions_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lr = pd.DataFrame()\n",
    "submission_lr[\"PhraseId\"] = test_data[\"PhraseId\"]\n",
    "submission_lr[\"Sentiment\"] = y_test_predictions_lr\n",
    "submission_lr.to_csv(\"./target_lr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(multi_class='multinomial', max_iter=1000, solver='lbfgs')\n",
    "\n",
    "# Train the model on the augmented dataset\n",
    "logreg.fit(X_train_tfidf_rf, y_train_rf)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_predictions_rf = logreg.predict(X_val_tfidf_rf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(val_data_rf['Sentiment'], y_val_predictions_rf)\n",
    "\n",
    "accuracy_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions_rf = logreg.predict(X_test_tfidf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rf = pd.DataFrame()\n",
    "submission_rf[\"PhraseId\"] = test_data[\"PhraseId\"]\n",
    "submission_rf[\"Sentiment\"] = y_test_predictions_rf\n",
    "submission_rf.to_csv(\"./target_rf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
